#!/usr/bin/env python3
"""
è¶…å‚æ•°æœç´¢ç»“æœåˆ†æè„šæœ¬
åˆ†æä¸åŒè¶…å‚æ•°ç»„åˆçš„æ€§èƒ½è¡¨ç°
"""

import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
import argparse

def format_maybe_float(value, fmt):
    try:
        if value is None:
            return "N/A"
        v = float(value)
        return format(v, fmt)
    except Exception:
        return str(value)


def parse_hp_from_dirname(dirname):
    """ä»ç›®å½•åè§£æè¶…å‚æ•°"""
    # æ ¼å¼: dalia_lr0.001_alpha0.3_beta0.4_gamma0.5 æˆ– stanfordAF_lr0.001_alpha0.3_beta0.4_gamma0.5
    try:
        parts = dirname.split('_')
        dataset = parts[0]  # ç¬¬ä¸€ä¸ªéƒ¨åˆ†æ˜¯æ•°æ®é›†å
        lr = float(parts[1].replace('lr', ''))
        alpha = float(parts[2].replace('alpha', ''))
        beta = float(parts[3].replace('beta', ''))
        gamma = float(parts[4].replace('gamma', '')) if len(parts) > 4 else None
        return dataset, lr, alpha, beta, gamma
    except:
        return None, None, None, None, None

def load_training_log(log_file):
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""
    try:
        with open(log_file, 'r') as f:
            data = json.load(f)
        return data
    except:
        return None

def extract_metrics(data):
    """æå–å…³é”®æŒ‡æ ‡"""
    if not data:
        return {}
    
    metrics = {}
    
    # å®éªŒä¿¡æ¯
    exp_info = data.get('experiment_info', {})
    metrics['compression_ratio'] = exp_info.get('compression_ratio', 'N/A')
    metrics['teacher_params'] = exp_info.get('teacher_params', {}).get('total', 'N/A')
    metrics['student_params'] = exp_info.get('student_params', {}).get('total', 'N/A')
    
    # æµ‹è¯•ç»“æœ
    test_results = data.get('test_results', {})
    metrics['test_loss'] = test_results.get('test_loss', 'N/A')
    
    test_metrics = test_results.get('test_metrics', {})
    if 'mse' in test_metrics:
        metrics['test_mse'] = test_metrics['mse']
    if 'mae' in test_metrics:
        metrics['test_mae'] = test_metrics['mae']
    if 'r2' in test_metrics:
        metrics['test_r2'] = test_metrics['r2']
    if 'accuracy' in test_metrics:
        metrics['test_accuracy'] = test_metrics['accuracy']
    if 'f1' in test_metrics:
        metrics['test_f1'] = test_metrics['f1']
    
    # æ€§èƒ½ç»Ÿè®¡
    performance_stats = test_results.get('test_performance', {})
    if 'avg_test_batches_per_second' in performance_stats:
        metrics['avg_test_batches_per_second'] = performance_stats['avg_test_batches_per_second']
    
    # ä»experiment_infoä¸­è·å–è®­ç»ƒæ€§èƒ½ç»Ÿè®¡
    exp_info = data.get('experiment_info', {})
    performance_stats = exp_info.get('performance_stats', {})
    if 'avg_train_batches_per_second' in performance_stats:
        metrics['avg_train_batches_per_second'] = performance_stats['avg_train_batches_per_second']
    
    return metrics

def analyze_hp_search(output_dir="./output_s/hp_search"):
    """åˆ†æè¶…å‚æ•°æœç´¢ç»“æœ"""
    output_path = Path(output_dir)
    
    if not output_path.exists():
        print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
        return
    
    results = []
    
    # éå†æ‰€æœ‰è¶…å‚æ•°ç»„åˆç›®å½•
    for hp_dir in output_path.iterdir():
        if not hp_dir.is_dir():
            continue
            
        dirname = hp_dir.name
        
        # è§£æè¶…å‚æ•°
        dataset, lr, alpha, beta, gamma = parse_hp_from_dirname(dirname)
        if lr is None:
            continue
            
        print(f"ğŸ“ åˆ†æç›®å½•: {dirname}")
        print(f"   æ•°æ®é›†: {dataset}")
        if gamma is not None:
            print(f"   è¶…å‚æ•°: lr={lr}, alpha={alpha}, beta={beta}, gamma={gamma}")
        else:
            print(f"   è¶…å‚æ•°: lr={lr}, alpha={alpha}, beta={beta}")
        
        # æŸ¥æ‰¾è®­ç»ƒæ—¥å¿—
        log_files = list(hp_dir.glob("*distill_training_log.json"))
        if not log_files:
            print(f"   âŒ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—")
            continue
            
        log_file = log_files[0]
        print(f"   ğŸ“„ è®­ç»ƒæ—¥å¿—: {log_file.name}")
        
        # åŠ è½½å¹¶åˆ†ææ—¥å¿—
        data = load_training_log(log_file)
        metrics = extract_metrics(data)
        
        # è®°å½•ç»“æœ
        result = {
            'dataset': dataset,
            'lr': lr,
            'alpha': alpha,
            'beta': beta,
            'dirname': dirname,
            **metrics
        }
        if gamma is not None:
            result['gamma'] = gamma
        results.append(result)
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        if 'test_loss' in metrics and metrics['test_loss'] != 'N/A':
            print(f"   ğŸ“Š æµ‹è¯•æŸå¤±: {metrics['test_loss']:.6f}")
        
        # æ ¹æ®æ•°æ®é›†ç±»å‹æ˜¾ç¤ºä¸åŒæŒ‡æ ‡
        if dataset == 'dalia':
            if 'test_mse' in metrics:
                print(f"   ğŸ“Š æµ‹è¯•MSE: {metrics['test_mse']:.6f}")
            if 'test_mae' in metrics:
                print(f"   ğŸ“Š æµ‹è¯•MAE: {metrics['test_mae']:.6f}")
        elif dataset == 'stanfordAF':
            if 'test_accuracy' in metrics:
                print(f"   ğŸ“Š æµ‹è¯•å‡†ç¡®ç‡: {metrics['test_accuracy']:.4f}")
            if 'test_f1' in metrics:
                print(f"   ğŸ“Š æµ‹è¯•F1: {metrics['test_f1']:.4f}")
        
        # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
        if 'avg_train_batches_per_second' in metrics:
            print(f"   ğŸš€ è®­ç»ƒæ‰¹æ¬¡/ç§’: {format_maybe_float(metrics['avg_train_batches_per_second'], '.2f')}")
        if 'avg_test_batches_per_second' in metrics:
            print(f"   ğŸš€ æµ‹è¯•æ‰¹æ¬¡/ç§’: {format_maybe_float(metrics['avg_test_batches_per_second'], '.2f')}")
        
        if 'compression_ratio' in metrics and metrics['compression_ratio'] != 'N/A':
            print(f"   ğŸ“Š å‹ç¼©æ¯”: {metrics['compression_ratio']}x")
        print()
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¶…å‚æ•°æœç´¢ç»“æœ")
        return
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(results)
    
    # æ’åºï¼ˆæŒ‰æµ‹è¯•æŸå¤±ï¼Œå¦‚æœæœ‰çš„è¯ï¼‰
    if 'test_loss' in df.columns and df['test_loss'].dtype != 'object':
        df = df.sort_values('test_loss')
    
    # ä¿å­˜åˆ†æç»“æœ
    output_file = "hp_search_analysis.csv"
    df.to_csv(output_file, index=False)
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # å°†æœ€ä½³testç»“æœæ±‡æ€»åˆ°ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼ˆæŒ‰æ•°æ®é›†æ ‡å‡†ï¼šdalia ä½¿ç”¨ test_mae æœ€å°ï¼›stanfordAF ä½¿ç”¨ test_f1 æœ€å¤§ï¼‰
    best_summary_rows = []
    best_overall_row = None

    # è§„èŒƒåŒ–æ•°å€¼åˆ—
    df_numeric = df.copy()
    if 'test_mae' in df_numeric.columns:
        df_numeric['test_mae'] = pd.to_numeric(df_numeric['test_mae'], errors='coerce')
    if 'test_f1' in df_numeric.columns:
        df_numeric['test_f1'] = pd.to_numeric(df_numeric['test_f1'], errors='coerce')

    # dalia æœ€ä½³ï¼ˆtest_mae æœ€å°ï¼‰
    if 'dataset' in df_numeric.columns and 'test_mae' in df_numeric.columns:
        dalia_df = df_numeric[df_numeric['dataset'] == 'dalia'].dropna(subset=['test_mae'])
        if not dalia_df.empty:
            best_dalia = dalia_df.loc[dalia_df['test_mae'].idxmin()]
            best_summary_rows.append({
                'scope': 'dataset:dalia',
                **{k: best_dalia.get(k, 'N/A') for k in [
                    'dataset','dirname','lr','alpha','beta','gamma',
                    'test_loss','test_mse','test_mae','test_accuracy','test_f1',
                    'avg_train_batches_per_second','avg_test_batches_per_second',
                    'compression_ratio','teacher_params','student_params'
                ]}
            })

    # stanfordAF æœ€ä½³ï¼ˆtest_f1 æœ€å¤§ï¼‰
    if 'dataset' in df_numeric.columns and 'test_f1' in df_numeric.columns:
        saf_df = df_numeric[df_numeric['dataset'] == 'stanfordAF'].dropna(subset=['test_f1'])
        if not saf_df.empty:
            best_saf = saf_df.loc[saf_df['test_f1'].idxmax()]
            best_summary_rows.append({
                'scope': 'dataset:stanfordAF',
                **{k: best_saf.get(k, 'N/A') for k in [
                    'dataset','dirname','lr','alpha','beta','gamma',
                    'test_loss','test_mse','test_mae','test_accuracy','test_f1',
                    'avg_train_batches_per_second','avg_test_batches_per_second',
                    'compression_ratio','teacher_params','student_params'
                ]}
            })

    # æ•´ä½“æœ€ä½³ï¼ˆä½¿ç”¨å¯æ¯”è¾ƒåˆ†æ•°ï¼šdalia ç”¨ test_maeï¼ŒstanfordAF ç”¨ -test_f1ï¼Œåˆ†æ•°è¶Šå°è¶Šå¥½ï¼‰
    candidates = []
    for row in best_summary_rows:
        if row.get('scope') == 'dataset:dalia' and pd.notna(row.get('test_mae')):
            candidates.append((row['test_mae'], row))
        elif row.get('scope') == 'dataset:stanfordAF' and pd.notna(row.get('test_f1')):
            candidates.append((-row['test_f1'], row))
    if candidates:
        candidates.sort(key=lambda x: x[0])
        best_overall_row = candidates[0][1].copy()
        best_overall_row['scope'] = 'overall'
        best_summary_rows.insert(0, best_overall_row)

    if best_summary_rows:
        best_summary_df = pd.DataFrame(best_summary_rows)
        best_output_file = "best_test_results.csv"
        best_summary_df.to_csv(best_output_file, index=False)
        print(f"âœ… æœ€ä½³æµ‹è¯•ç»“æœå·²æ±‡æ€»åˆ°: {best_output_file}")
    else:
        print("âš ï¸ æœªèƒ½æ ¹æ®æ•°æ®é›†æ ‡å‡†ç”Ÿæˆæœ€ä½³ç»“æœæ±‡æ€»ï¼ˆå¯èƒ½ç¼ºå°‘ test_mae æˆ– test_f1ï¼‰")

    # æ˜¾ç¤ºæœ€ä½³ç»“æœï¼ˆä¾æ®æ•°æ®é›†æ ‡å‡†ï¼‰
    print("\nğŸ† æœ€ä½³è¶…å‚æ•°ç»„åˆ:")
    if 'best_overall_row' in locals() and best_overall_row is not None:
        best_row = best_overall_row
        if pd.notna(best_row.get('test_loss')):
            print(f"   æµ‹è¯•æŸå¤±: {best_row['test_loss']:.6f}")
        print(f"   æ•°æ®é›†: {best_row['dataset']}")

        if best_row['dataset'] == 'dalia':
            if pd.notna(best_row.get('test_mse')):
                print(f"   æµ‹è¯•MSE: {best_row['test_mse']:.6f}")
            if pd.notna(best_row.get('test_mae')):
                print(f"   æµ‹è¯•MAE: {best_row['test_mae']:.6f}")
        elif best_row['dataset'] == 'stanfordAF':
            if pd.notna(best_row.get('test_accuracy')):
                print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_row['test_accuracy']:.4f}")
            if pd.notna(best_row.get('test_f1')):
                print(f"   æµ‹è¯•F1: {best_row['test_f1']:.4f}")

        if pd.notna(best_row.get('avg_train_batches_per_second')):
            print(f"   è®­ç»ƒæ‰¹æ¬¡/ç§’: {format_maybe_float(best_row['avg_train_batches_per_second'], '.2f')}")
        if pd.notna(best_row.get('avg_test_batches_per_second')):
            print(f"   æµ‹è¯•æ‰¹æ¬¡/ç§’: {format_maybe_float(best_row['avg_test_batches_per_second'], '.2f')}")

        print(f"   å­¦ä¹ ç‡: {best_row['lr']}")
        print(f"   Alpha: {best_row['alpha']}")
        print(f"   Beta: {best_row['beta']}")
        if 'gamma' in best_row and pd.notna(best_row['gamma']):
            print(f"   Gamma: {best_row['gamma']}")
        print(f"   ç›®å½•: {best_row['dirname']}")
    
    # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
    print(f"\nğŸ“‹ æ‰€æœ‰è¶…å‚æ•°ç»„åˆç»“æœ (å…±{len(df)}ä¸ª):")
    print(df.to_string(index=False))
    
    # ç»Ÿè®¡åˆ†æ
    print(f"\nğŸ“Š ç»Ÿè®¡åˆ†æ:")
    if 'test_loss' in df.columns and df['test_loss'].dtype != 'object':
        print(f"   æµ‹è¯•æŸå¤±èŒƒå›´: {df['test_loss'].min():.6f} - {df['test_loss'].max():.6f}")
        print(f"   æµ‹è¯•æŸå¤±å‡å€¼: {df['test_loss'].mean():.6f}")
        print(f"   æµ‹è¯•æŸå¤±æ ‡å‡†å·®: {df['test_loss'].std():.6f}")
    
    # æ ¹æ®æ•°æ®é›†ç±»å‹æ˜¾ç¤ºä¸åŒæŒ‡æ ‡çš„ç»Ÿè®¡
    dalia_df = df[df['dataset'] == 'dalia']
    stanfordAF_df = df[df['dataset'] == 'stanfordAF']
    
    if not dalia_df.empty:
        print(f"\n   ğŸ“Š DALIAæ•°æ®é›†ç»Ÿè®¡ ({len(dalia_df)}ä¸ªç»“æœ):")
        if 'test_mse' in dalia_df.columns and dalia_df['test_mse'].dtype != 'object':
            print(f"     æµ‹è¯•MSEèŒƒå›´: {dalia_df['test_mse'].min():.6f} - {dalia_df['test_mse'].max():.6f}")
            print(f"     æµ‹è¯•MSEå‡å€¼: {dalia_df['test_mse'].mean():.6f}")
        if 'test_mae' in dalia_df.columns and dalia_df['test_mae'].dtype != 'object':
            print(f"     æµ‹è¯•MAEèŒƒå›´: {dalia_df['test_mae'].min():.6f} - {dalia_df['test_mae'].max():.6f}")
            print(f"     æµ‹è¯•MAEå‡å€¼: {dalia_df['test_mae'].mean():.6f}")
    
    if not stanfordAF_df.empty:
        print(f"\n   ğŸ“Š StanfordAFæ•°æ®é›†ç»Ÿè®¡ ({len(stanfordAF_df)}ä¸ªç»“æœ):")
        if 'test_accuracy' in stanfordAF_df.columns and stanfordAF_df['test_accuracy'].dtype != 'object':
            print(f"     æµ‹è¯•å‡†ç¡®ç‡èŒƒå›´: {stanfordAF_df['test_accuracy'].min():.4f} - {stanfordAF_df['test_accuracy'].max():.4f}")
            print(f"     æµ‹è¯•å‡†ç¡®ç‡å‡å€¼: {stanfordAF_df['test_accuracy'].mean():.4f}")
        if 'test_f1' in stanfordAF_df.columns and stanfordAF_df['test_f1'].dtype != 'object':
            print(f"     æµ‹è¯•F1èŒƒå›´: {stanfordAF_df['test_f1'].min():.4f} - {stanfordAF_df['test_f1'].max():.4f}")
            print(f"     æµ‹è¯•F1å‡å€¼: {stanfordAF_df['test_f1'].mean():.4f}")
    
    # æ€§èƒ½ç»Ÿè®¡
    print(f"\n   ğŸš€ æ€§èƒ½ç»Ÿè®¡:")
    if 'avg_train_batches_per_second' in df.columns and df['avg_train_batches_per_second'].dtype != 'object':
        valid_train_speeds = df['avg_train_batches_per_second'].dropna()
        if not valid_train_speeds.empty:
            print(f"     è®­ç»ƒæ‰¹æ¬¡/ç§’èŒƒå›´: {valid_train_speeds.min():.2f} - {valid_train_speeds.max():.2f}")
            print(f"     è®­ç»ƒæ‰¹æ¬¡/ç§’å‡å€¼: {valid_train_speeds.mean():.2f}")
    
    if 'avg_test_batches_per_second' in df.columns and df['avg_test_batches_per_second'].dtype != 'object':
        valid_test_speeds = df['avg_test_batches_per_second'].dropna()
        if not valid_test_speeds.empty:
            print(f"     æµ‹è¯•æ‰¹æ¬¡/ç§’èŒƒå›´: {valid_test_speeds.min():.2f} - {valid_test_speeds.max():.2f}")
            print(f"     æµ‹è¯•æ‰¹æ¬¡/ç§’å‡å€¼: {valid_test_speeds.mean():.2f}")
    
    # è¶…å‚æ•°å½±å“åˆ†æ
    print(f"\nğŸ” è¶…å‚æ•°å½±å“åˆ†æ:")
    
    # å­¦ä¹ ç‡å½±å“
    lr_groups = df.groupby('lr')
    if 'test_loss' in df.columns and df['test_loss'].dtype != 'object':
        print("   å­¦ä¹ ç‡å½±å“:")
        for lr, group in lr_groups:
            avg_loss = group['test_loss'].mean()
            print(f"     lr={lr}: å¹³å‡æŸå¤±={avg_loss:.6f}")
    
    # Alphaå½±å“
    alpha_groups = df.groupby('alpha')
    if 'test_loss' in df.columns and df['test_loss'].dtype != 'object':
        print("   Alphaå½±å“:")
        for alpha, group in alpha_groups:
            avg_loss = group['test_loss'].mean()
            print(f"     alpha={alpha}: å¹³å‡æŸå¤±={avg_loss:.6f}")
    
    # Betaå½±å“
    beta_groups = df.groupby('beta')
    if 'test_loss' in df.columns and df['test_loss'].dtype != 'object':
        print("   Betaå½±å“:")
        for beta, group in beta_groups:
            avg_loss = group['test_loss'].mean()
            print(f"     beta={beta}: å¹³å‡æŸå¤±={avg_loss:.6f}")
    
    # Gammaå½±å“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'gamma' in df.columns:
        gamma_groups = df.groupby('gamma')
        if 'test_loss' in df.columns and df['test_loss'].dtype != 'object':
            print("   Gammaå½±å“:")
            for gamma, group in gamma_groups:
                avg_loss = group['test_loss'].mean()
                print(f"     gamma={gamma}: å¹³å‡æŸå¤±={avg_loss:.6f}")
    
    # æ•°æ®é›†å½±å“ï¼ˆæ˜¾ç¤ºæ•°æ®é›†ç‰¹å®šçš„æŒ‡æ ‡ï¼‰
    dataset_groups = df.groupby('dataset')
    print("   æ•°æ®é›†å½±å“:")
    for dataset, group in dataset_groups:
        if dataset == 'dalia':
            if 'test_mse' in group.columns and group['test_mse'].dtype != 'object':
                avg_mse = group['test_mse'].mean()
                print(f"     {dataset}: å¹³å‡MSE={avg_mse:.6f}")
            if 'test_mae' in group.columns and group['test_mae'].dtype != 'object':
                avg_mae = group['test_mae'].mean()
                print(f"     {dataset}: å¹³å‡MAE={avg_mae:.6f}")
        elif dataset == 'stanfordAF':
            if 'test_accuracy' in group.columns and group['test_accuracy'].dtype != 'object':
                avg_acc = group['test_accuracy'].mean()
                print(f"     {dataset}: å¹³å‡å‡†ç¡®ç‡={avg_acc:.4f}")
            if 'test_f1' in group.columns and group['test_f1'].dtype != 'object':
                avg_f1 = group['test_f1'].mean()
                print(f"     {dataset}: å¹³å‡F1={avg_f1:.4f}")
    
    return df

def main():
    parser = argparse.ArgumentParser(description='åˆ†æè¶…å‚æ•°æœç´¢ç»“æœ')
    parser.add_argument('--output_dir', type=str, default='./output_s/hp_search',
                       help='è¶…å‚æ•°æœç´¢è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("ğŸ” å¼€å§‹åˆ†æè¶…å‚æ•°æœç´¢ç»“æœ...")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print()
    
    results_df = analyze_hp_search(args.output_dir)
    
    if results_df is not None:
        print(f"\nâœ… åˆ†æå®Œæˆï¼å…±åˆ†æäº† {len(results_df)} ä¸ªè¶…å‚æ•°ç»„åˆ")
    else:
        print("\nâŒ åˆ†æå¤±è´¥")

if __name__ == "__main__":
    main() 